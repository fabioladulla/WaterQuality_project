{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c688e13-5364-41dd-bbdf-1579166a5532",
   "metadata": {},
   "source": [
    "### ML Models with Upsampling + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e1b3c7-05da-45f8-96f7-d3417e695d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e13d9de-00b4-406d-82a1-81b844e5ea99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.584087</td>\n",
       "      <td>188.313324</td>\n",
       "      <td>28748.687739</td>\n",
       "      <td>7.544869</td>\n",
       "      <td>326.678363</td>\n",
       "      <td>280.467916</td>\n",
       "      <td>8.399735</td>\n",
       "      <td>54.917862</td>\n",
       "      <td>2.559708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.223862</td>\n",
       "      <td>248.071735</td>\n",
       "      <td>28749.716544</td>\n",
       "      <td>7.513408</td>\n",
       "      <td>393.663396</td>\n",
       "      <td>283.651634</td>\n",
       "      <td>13.789695</td>\n",
       "      <td>84.603556</td>\n",
       "      <td>2.672989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.635849</td>\n",
       "      <td>203.361523</td>\n",
       "      <td>13672.091764</td>\n",
       "      <td>4.563009</td>\n",
       "      <td>303.309771</td>\n",
       "      <td>474.607645</td>\n",
       "      <td>12.363817</td>\n",
       "      <td>62.798309</td>\n",
       "      <td>4.401425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "1   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "2   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
       "3  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
       "4   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       18.436524       100.341674   4.628771           0  \n",
       "1       11.558279        31.997993   4.075075           0  \n",
       "2        8.399735        54.917862   2.559708           0  \n",
       "3       13.789695        84.603556   2.672989           0  \n",
       "4       12.363817        62.798309   4.401425           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned_df.csv file\n",
    "cleaned_df = pd.read_csv('../data/clean/cleaned_df.csv')\n",
    "# Read the file and its shape\n",
    "display(cleaned_df.head())\n",
    "print(cleaned_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3aeb2-9d7d-4b67-9096-63626c5a6e90",
   "metadata": {},
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb5135b-06bc-41d2-aaee-14be3340cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features from the target\n",
    "y = cleaned_df['Potability']\n",
    "X = cleaned_df.drop(['Potability'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee160651-d0e7-4acb-aedb-f1e0bdd6a119",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35635bbc-36c5-4d1d-b785-ac1644c32e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df34e50-e81b-4735-b7b1-f12d4c453af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd6de92a-d923-48ea-97fe-6d7c8e82f9c6",
   "metadata": {},
   "source": [
    "### Balance Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a610396f-fc09-4fc3-9e21-300bf96b056e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Potability\n",
       "0    845\n",
       "1    845\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=123)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3e4b93-7e5f-40ac-9115-a5cd48d7e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate X_train and y_train\n",
    "trainset = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a979855-81bd-4e76-9376-e00286fa2c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Potability\n",
       "0    845\n",
       "1    562\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique value count of target column\n",
    "trainset['Potability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dc5ef01-682c-4a8c-8892-8aaf493e9199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's upsample the minority \n",
    "from sklearn.utils import resample\n",
    "df_majority = trainset[trainset['Potability'] == 0]\n",
    "df_minority = trainset[trainset['Potability'] == 1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "trainset1 = pd.concat([df_majority, df_minority_upsampled], axis=0)\n",
    "trainset1\n",
    "\n",
    "X_train_upsampled = trainset1.drop(['Potability'], axis =1)\n",
    "y_train_upsampled = trainset1['Potability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "339a9560-7ec3-46da-b605-d7da0ecf8f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3380, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate X_train_smote and X_train_upsampled\n",
    "X_train1 = pd.concat([X_train_smote, X_train_upsampled])\n",
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60132b9d-34fe-4f62-8d5c-1f1ec702ff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3380,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate y_train_smote and y_train_upsampled\n",
    "y_train1 = pd.concat([y_train_smote, y_train_upsampled])\n",
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bea243-b5df-4921-a478-f67619709941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4000aa0-6d91-4000-803f-4836f5a16064",
   "metadata": {},
   "source": [
    "### Scale Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90d42259-8aed-4797-b2df-6aad26a92674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler with TRAIN data\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "# Scale X_train_num_transformed with fitted scaler. Output is a np.array.\n",
    "X_train_scaled = scaler.transform(X_train1)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Add columns to np.array to create a DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, \n",
    "                                 columns=X_train1.columns, \n",
    "                                 index=X_train1.index)\n",
    "\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, \n",
    "                                columns=X_test.columns,\n",
    "                                index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3156f8b3-5df6-40d8-bc5e-16c4b4e5d77b",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "038830d3-d030-44fe-8f31-3a1d2a62298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic Regression': 0.5292899408284024, 'Random Forest Classifier': 0.9674556213017752, 'KNN': 0.7775147928994084, 'AdaBoostClassifier': 0.6434911242603552, 'GradientBoostingClassifier': 0.7739644970414201}\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "model1 = LogisticRegression()\n",
    "model2 = RandomForestClassifier()\n",
    "model3 = KNeighborsClassifier()\n",
    "model4 = AdaBoostClassifier()\n",
    "model5 = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "model_pipeline = [model1, model2, model3, model4, model5]\n",
    "model_names = ['Logistic Regression', 'Random Forest Classifier', 'KNN', 'AdaBoostClassifier', 'GradientBoostingClassifier']\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for model, model_name in zip(model_pipeline, model_names):\n",
    "    mean_score = np.mean(cross_val_score(model, X_train_scaled_df, y_train1, cv=5))\n",
    "    scores[model_name] = mean_score\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e066a96b-0775-4de2-b686-95d28a4814f3",
   "metadata": {},
   "source": [
    "### Playing with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d1ce22a-e069-48b9-aa7b-47a540e86a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Accuracy:\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Score: 0.9355\n",
      "------\n",
      "Best parameters for Precision:\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 15, 'n_estimators': 150}\n",
      "Score: 0.9738\n",
      "------\n",
      "Best parameters for Kappa:\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Score: 0.8710\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False],\n",
    "    'min_samples_split': [5, 10, 15],\n",
    "    'min_samples_leaf' : [10, 20],\n",
    "    'max_depth':[5, 10, 20],\n",
    "}\n",
    "\n",
    "# Multiple scoring metrics\n",
    "scoring = {\n",
    "    'Accuracy': 'accuracy',\n",
    "    'Precision': 'precision',\n",
    "    'Kappa': make_scorer(cohen_kappa_score)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, scoring=scoring, refit=False, cv=5)\n",
    "grid_search.fit(X_train_scaled_df,y_train1)\n",
    "\n",
    "# Retrieve best parameters and best score for each scoring metric\n",
    "for metric_name in scoring.keys():\n",
    "    print(f\"Best parameters for {metric_name}:\")\n",
    "    index = grid_search.cv_results_['rank_test_' + metric_name].argmin()\n",
    "    params = grid_search.cv_results_['params'][index]\n",
    "    best_score = grid_search.cv_results_['mean_test_' + metric_name][index]\n",
    "    print(\"Parameters:\", params)\n",
    "    print(f\"Score: {best_score:.4f}\")\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66a75e11-11a0-4b68-8e38-730e0e90193c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for the Random Forest in the TRAIN set is 0.99\n",
      "The Accuracy for the Random Forest in the TEST  set is 0.64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Potability\n",
       "0    355\n",
       "1    249\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[250, 105],\n",
       "       [113, 136]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get predictions\n",
    "clf = RandomForestClassifier(max_depth=20,\n",
    "                             min_samples_split=15,\n",
    "                             min_samples_leaf =10,\n",
    "                             n_estimators=50,\n",
    "                            bootstrap=False,\n",
    "                            max_features='sqrt',\n",
    "                            criterion='entropy')\n",
    "\n",
    "clf.fit(X_train_scaled_df, y_train1)\n",
    "\n",
    "print(\"The Accuracy for the Random Forest in the TRAIN set is {:.2f}\".format(clf.score(X_train_scaled_df, y_train1)))\n",
    "print(\"The Accuracy for the Random Forest in the TEST  set is {:.2f}\".format(clf.score(X_test_scaled_df, y_test)))\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled_df)\n",
    "display(y_test.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38a112a8-1198-4ddd-8c26-a3148de5a9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70       355\n",
      "           1       0.56      0.55      0.56       249\n",
      "\n",
      "    accuracy                           0.64       604\n",
      "   macro avg       0.63      0.63      0.63       604\n",
      "weighted avg       0.64      0.64      0.64       604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find other metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660065b6-501f-49af-bc16-5dd5145493aa",
   "metadata": {},
   "source": [
    "### Feature Importance Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f965b4e-5b95-4f43-97b3-4eb77e8dfa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.17106501462431903, 'ph'),\n",
       " (0.1455160095185526, 'Sulfate'),\n",
       " (0.12089342693258448, 'Chloramines'),\n",
       " (0.12070560045156185, 'Solids'),\n",
       " (0.11051370215344977, 'Hardness'),\n",
       " (0.09453636263914919, 'Turbidity'),\n",
       " (0.08501361575277308, 'Trihalomethanes'),\n",
       " (0.07657834747858894, 'Organic_carbon'),\n",
       " (0.07517792044902104, 'Conductivity')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature importances\n",
    "rf_importances = list(zip(clf.feature_importances_, cleaned_df.columns))\n",
    "rf_importances.sort(reverse=True)\n",
    "# Print the feature rankings\n",
    "rf_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "686283c0-206b-4508-8732-02d5a40b1717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Potability\n",
       "1317           1\n",
       "526            0\n",
       "393            0\n",
       "1405           1\n",
       "433            0\n",
       "...          ...\n",
       "1791           1\n",
       "836            0\n",
       "1642           1\n",
       "1523           0\n",
       "575            0\n",
       "\n",
       "[604 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe of the predictions y_pred\n",
    "y_pred = clf.predict(X_test_scaled_df)\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['Potability'], index=X_test_scaled_df.index)\n",
    "y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61e9da-22f4-46a2-bca6-3f20eb923b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalproject_env",
   "language": "python",
   "name": "finalproject_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
